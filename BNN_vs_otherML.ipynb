{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOTzFgL7mIRccyNDtWG7a0w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"d1i54K8nzm7Z"},"outputs":[],"source":["# For Prediction of Drug-Induced Liver Injuries using ML/AI Methods.\n","# Neural Network, Bayesian Neural Network (Basic), NuSVC, and Probabilistic Odds Logistic Regression (POLR) Model\n","# Advanced BNN is seperated written in the following file\n","\n","#*******************************************\n","# Developed by: Ashok K Sharma\n","# Completed on: May 25th - June 6th, 2023\n","#******************************************"]},{"cell_type":"code","source":["# Function to count and sort the unique elements in the input data\n","def sort_map(input_data):\n","    # Get the unique elements and their counts\n","    unique, counts = np.unique(input_data, return_counts=True)\n","    # Create a dictionary mapping each unique element to its count\n","    count_dict = dict(zip(unique, counts))\n","    # Sort the dictionary and return it\n","    return sorted(count_dict.items())\n","\n","# Read the train and test datasets\n","train_data = pd.read_csv(\"Code_check/1-s2.0-S2468111320300438-mmc8.csv\")\n","test_data = pd.read_csv(\"Code_check/1-s2.0-S2468111320300438-mmc10.csv\")\n","\n","# Select the desired features from the datasets\n","features = ['ClogP', 'BSEP', 'Glu', 'Glu_Gal', 'THLE', 'HepG2', 'Fsp3', 'log10cmax']\n","X_train_df = train_data[features]\n","X_test_df = test_data[features]\n","\n","# Initialize a StandardScaler to standardize the features to have mean=0 and variance=1\n","scaler = StandardScaler()\n","\n","# Fit the StandardScaler on the training data and transform both training and test data\n","scaler.fit(X_train_df)\n","X_train = pd.DataFrame(scaler.transform(X_train_df), columns=X_train_df.columns)\n","X_test = pd.DataFrame(scaler.transform(X_test_df), columns=X_test_df.columns)\n","\n","# Select the target variable\n","target = ['dili_sev']\n","Y_train = (train_data[target].values.astype(int) - 1)\n","Y_test = (test_data[target].values.astype(int) - 1)\n","\n","# Apply the sort_map function on the target variable\n","sorted_train_output = sort_map(Y_train)\n","sorted_test_output = sort_map(Y_test)\n","\n","# Print the sorted output\n","print(sorted_train_output)\n","print(sorted_test_output)"],"metadata":{"id":"Yb51JZV70K6G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- This segment Specifically Needs to Run NN, and BNN\n","# Set the device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Convert numpy arrays to PyTorch tensors\n","X_train = torch.from_numpy(X_train.values).float().to(device)\n","Y_train = torch.from_numpy(Y_train.flatten()).long().to(device)\n","X_test = torch.from_numpy(X_test.values).float().to(device)\n","Y_test = torch.from_numpy(Y_test.flatten()).long().to(device)"],"metadata":{"id":"-yL22kB90Pv_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1. Create a Neural Network Model"],"metadata":{"id":"sR2mlKMO0TJW"}},{"cell_type":"code","source":["def set_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","\n","# Define the Feedforward Neural Network\n","class FFNN(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(FFNN, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","        self.fc3 = nn.Linear(hidden_dim, output_dim)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        out = self.relu(out)\n","        out = self.fc3(out)\n","        return out\n","\n","# set_seed(123), set_seed(34), set_seed(91)\n","set_seed(91)\n","\n","# Set the device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Define dimensions\n","input_dim = X_train.shape[1] # It should match with the number of features in the dataset\n","hidden_dim = 128 # You can change this\n","output_dim = len(np.unique(Y_train)) # It should match with the number of unique target values\n","\n","# Create the model\n","model = FFNN(input_dim, hidden_dim, output_dim).to(device)\n","\n","# Define the loss function and the optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters())\n","\n","\n","# Train the model\n","epochs = 450 # You can change this\n","model.train()\n","for epoch in range(epochs):\n","    optimizer.zero_grad()\n","    outputs = model(X_train)\n","    loss = criterion(outputs, Y_train)\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Calculate train accuracy and confusion matrix in each epoch\n","    _, predicted_nn = torch.max(outputs.data, 1)\n","    train_accuracy = 100 * (predicted_nn == Y_train).sum().item() / len(Y_train)\n","    conf_matrix = confusion_matrix(Y_train.cpu(), predicted_nn.cpu())\n","\n","\n","#     if (epoch+1) % 10 == 0:\n","#         print(f'Epoch {epoch+1}, Loss: {loss.item()}, Train Accuracy: {train_accuracy}%')\n","\n","print('Confusion Matrix:')\n","print(conf_matrix)\n","\n","# Evaluate the model\n","model.eval()\n","with torch.no_grad():\n","    outputs = model(X_test)\n","    _, predicted_nn = torch.max(outputs.data, 1)\n","    correct = (predicted_nn == Y_test).sum().item()\n","    conf_matrix = confusion_matrix(Y_test.cpu(), predicted_nn.cpu())\n","    print(f'Accuracy of the model on the test set: {100 * correct / len(Y_test)}%')\n","    print('Confusion Matrix:')\n","    print(conf_matrix)"],"metadata":{"id":"JC8wR13Z0SiP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print Actual labels and Predictions\n","Y_test, predicted_nn"],"metadata":{"id":"v-XpVU220dYy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model\n","model.eval()\n","with torch.no_grad():\n","    outputs = model(X_test)\n","    # Convert the output probabilities to predicted class\n","    _, predicted_nn = torch.max(outputs.data, 1)\n","    correct = (predicted_nn == Y_test).sum().item()\n","\n","    # Compute the probabilities via softmax\n","    probabilities_nn = torch.nn.functional.softmax(outputs, dim=1)\n","    print('Predicted Probabilities:', probabilities_nn)\n","    print('Predicted :', predicted_nn)\n","    print(f'Accuracy of the model on the test set: {100 * correct / len(Y_test)}%')"],"metadata":{"id":"4BB4L2hA0iHl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#----- Save Different Performance Matrices\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, precision_score, accuracy_score, f1_score, matthews_corrcoef, confusion_matrix\n","\n","# Compute precision, accuracy, F1-score, and MCC for the predicted and true labels\n","precision = precision_score(Y_test, predicted_nn, average='macro')\n","accuracy = accuracy_score(Y_test, predicted_nn)\n","f1_score = f1_score(Y_test, predicted_nn, average='macro')\n","mcc = matthews_corrcoef(Y_test, predicted_nn)\n","\n","# Calculate sensitivity and specificity using confusion matrix\n","cm = confusion_matrix(Y_test, predicted_nn)\n","\n","# Calculate sensitivity and specificity for each class\n","sensitivity = {}\n","specificity = {}\n","\n","for i in range(cm.shape[0]):\n","    tp = cm[i, i]\n","    fn = sum(cm[i, :]) - tp\n","    fp = sum(cm[:, i]) - tp\n","    tn = cm.sum() - (tp + fn + fp)\n","\n","    sensitivity[i] = tp / (tp + fn)\n","    specificity[i] = tn / (tn + fp)\n","\n","# Calculate overall sensitivity and specificity\n","overall_sensitivity = sum(sensitivity.values()) / len(sensitivity)\n","overall_specificity = sum(specificity.values()) / len(specificity)\n","\n","# Print the performance metrics to the console\n","print(\"***************** MODEL PERFORMANCE: ****************\")\n","print(\"Confusion Matrix:\")\n","print(cm)\n","print(\"Sensitivity:\")\n","for key, value in sensitivity.items():\n","    print(\"Class {}: {:.2f}\".format(key, value))\n","print(\"Specificity:\")\n","for key, value in specificity.items():\n","    print(\"Class {}: {:.2f}\".format(key, value))\n","print(\"Overall Sensitivity: {:.2f}\".format(overall_sensitivity))\n","print(\"Overall Specificity: {:.2f}\".format(overall_specificity))\n","\n","print(\"Precision: {:.2f}\".format(precision))\n","print(\"Accuracy: {:.2f}\".format(accuracy))\n","print(\"F1-score: {:.2f}\".format(f1_score))\n","print(\"MCC: {:.2f}\".format(mcc))"],"metadata":{"id":"41byDfOY0k7o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###### To Save Neural Network Outputs- Original Labels, Predicted lables, Probabilities, Drug Names Along with Variable Scaler values\n","#!mkdir = ML_results # One time Taks and Done\n","merged_array_nn = np.column_stack((Y_test, predicted_nn))\n","merged_array_nn_df = pd.DataFrame(data=merged_array_nn, columns=['Y_test', 'Y_predicted'])\n","#print(merged_array_nn_df)\n","\n","# Convert predicted probabilities to a NumPy array\n","probs_array_nn = probabilities_nn.detach().numpy()\n","# Create a DataFrame from the NumPy array\n","probs_df_nn = pd.DataFrame(probs_array_nn, columns=['Class 0', 'Class 1', 'Class 2'])  # Add column names as per your classes\n","# Print the DataFrame\n","#print(probs_df_nn)\n","\n","#-- Get the Drug names from Test Dataset and Scaler values of All variables\n","drug_names = test_data[['Drug']]\n","numpy_array = X_test.numpy()\n","X_test_scaler_df = pd.DataFrame(numpy_array, columns =X_test_df.columns)\n","#X_test_scaler_df\n","\n","#--- Merge Y_Test_Labels, Y_preds, Y_preds_Proabilites and test Dataset information also\n","concatenated_df_nn = pd.concat([merged_array_nn_df, probs_df_nn, drug_names, X_test_scaler_df], axis=1)\n","print (concatenated_df_nn)\n","\n","#concatenated_df_nn.to_csv('ML_results/Neural_nets_Preds.csv', index=False)  # Specify the desired file name and path"],"metadata":{"id":"5PgsHVy50orN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Create Bayesian Neural Network"],"metadata":{"id":"vag7-lNO021e"}},{"cell_type":"code","source":["def set_seed(seed):\n","    torch.manual_seed(seed)\n","    pyro.set_rng_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","# Define the Bayesian Feedforward Neural Network\n","class BayesianFFNN(pyro.nn.PyroModule):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(BayesianFFNN, self).__init__()\n","        self.fc1 = pyro.nn.PyroModule[nn.Linear](input_dim, hidden_dim)\n","        self.fc1.weight = pyro.nn.PyroSample(dist.Normal(0., 1.).expand([hidden_dim, input_dim]).to_event(2))\n","        self.fc1.bias = pyro.nn.PyroSample(dist.Normal(0., 1.).expand([hidden_dim]).to_event(1))\n","        self.fc3 = pyro.nn.PyroModule[nn.Linear](hidden_dim, output_dim)\n","        self.fc3.weight = pyro.nn.PyroSample(dist.Normal(0., 1.).expand([output_dim, hidden_dim]).to_event(2))\n","        self.fc3.bias = pyro.nn.PyroSample(dist.Normal(0., 1.).expand([output_dim]).to_event(1))\n","\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x, y=None):\n","        out = self.relu(self.fc1(x))\n","        out = self.fc3(out)\n","        with pyro.plate(\"data\", x.shape[0]):\n","            obs = pyro.sample(\"obs\", dist.Categorical(logits=out), obs=y)\n","        return out\n","\n","# set_seed(25, 234) ~ 40%\n","# set_seed(234) ~ 45%\n","# set_seed(91) ~54%\n","\n","set_seed(91)\n","\n","# Set the device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Define dimensions\n","input_dim = X_train.shape[1]\n","hidden_dim = 32\n","output_dim = len(np.unique(Y_train))\n","\n","# Create the model\n","model = BayesianFFNN(input_dim, hidden_dim, output_dim).to(device)\n","guide = pyro.infer.autoguide.AutoDiagonalNormal(model)\n","\n","# Define the loss function and the optimizer\n","optimizer = Adam({\"lr\": 0.15})\n","svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n","\n","\n","\n","# Train the model\n","epochs = 73\n","for epoch in range(epochs):\n","    model.train()\n","\n","    loss = svi.step(X_train, Y_train)\n","\n","    # Calculate train accuracy and confusion matrix in each epoch\n","    predicted = torch.argmax(model(X_train), dim=-1, keepdim=True)\n","    train_accuracy = 100 * (predicted.squeeze() == Y_train).sum().item() / len(Y_train)\n","    conf_matrix = confusion_matrix(Y_train.cpu(), predicted.cpu().squeeze())\n","\n","    if (epoch+1) % 50 == 0:\n","       print(f'Epoch {epoch+1}, Loss: {loss}, Train Accuracy: {train_accuracy}%')\n","\n","#     print('Confusion Matrix:')\n","#     print(conf_matrix)\n","\n","    # Evaluate the model\n","\n","    model.eval()\n","    with torch.no_grad():\n","        num_samples = 100\n","        sampled_models = [guide(X_test) for _ in range(num_samples)]\n","        outputs = torch.stack([model.forward(X_test) for _ in sampled_models]).mean(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct = (predicted == Y_test).sum().item()\n","        conf_matrix = confusion_matrix(Y_test.cpu(), predicted.cpu())\n","        print(f'Accuracy of the model on the test set: {epoch+1} {100 * correct / len(Y_test)}%')\n","        print('Confusion Matrix:')\n","        print(conf_matrix)"],"metadata":{"id":"yR9O0guH0y9l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print Actual Labels and Predictions.\n","Y_test, predicted"],"metadata":{"id":"V1GiAPNW09ZU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probabilities = torch.nn.functional.softmax(outputs, dim=1)\n","print('Prediction Probabilities:')\n","print(probabilities)"],"metadata":{"id":"ASkXTVFc1AIc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#----- Save Different Performance Matrices\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, precision_score, accuracy_score, f1_score, matthews_corrcoef, confusion_matrix\n","\n","# Compute precision, accuracy, F1-score, and MCC for the predicted and true labels\n","precision = precision_score(Y_test, predicted, average='macro')\n","accuracy = accuracy_score(Y_test, predicted)\n","f1_score = f1_score(Y_test, predicted, average='macro')\n","mcc = matthews_corrcoef(Y_test, predicted)\n","\n","# Calculate sensitivity and specificity using confusion matrix\n","cm = confusion_matrix(Y_test, predicted)\n","\n","# Calculate sensitivity and specificity for each class\n","sensitivity = {}\n","specificity = {}\n","\n","for i in range(cm.shape[0]):\n","    tp = cm[i, i]\n","    fn = sum(cm[i, :]) - tp\n","    fp = sum(cm[:, i]) - tp\n","    tn = cm.sum() - (tp + fn + fp)\n","\n","    sensitivity[i] = tp / (tp + fn)\n","    specificity[i] = tn / (tn + fp)\n","\n","# Calculate overall sensitivity and specificity\n","overall_sensitivity = sum(sensitivity.values()) / len(sensitivity)\n","overall_specificity = sum(specificity.values()) / len(specificity)\n","\n","# Print the performance metrics to the console\n","print(\"**************** MODEL PERFORMANCE: Bayesian Neural Network****************\")\n","print(\"Confusion Matrix:\")\n","print(cm)\n","print(\"Sensitivity:\")\n","for key, value in sensitivity.items():\n","    print(\"Class {}: {:.2f}\".format(key, value))\n","print(\"Specificity:\")\n","for key, value in specificity.items():\n","    print(\"Class {}: {:.2f}\".format(key, value))\n","print(\"Overall Sensitivity: {:.2f}\".format(overall_sensitivity))\n","print(\"Overall Specificity: {:.2f}\".format(overall_specificity))\n","\n","print(\"Precision: {:.2f}\".format(precision))\n","print(\"Accuracy: {:.2f}\".format(accuracy))\n","print(\"F1-score: {:.2f}\".format(f1_score))\n","print(\"MCC: {:.2f}\".format(mcc))"],"metadata":{"id":"Ma03x4dl1Cqh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###### To Save Bayesian Neural Network Outputs- Original Labels, Predicted lables, Probabilities, Drug Names Along with Variable Scaler values\n","# Save the Bayesian Neural Network Results\n","merged_array = np.column_stack((Y_test, predicted))\n","df = pd.DataFrame(data=merged_array, columns=['Y_test', 'Y_predicted'])\n","#print (df)\n","\n","# Convert predicted probabilities to a NumPy array\n","probs_array = probabilities.detach().numpy()\n","# Create a DataFrame from the NumPy array\n","probs_df = pd.DataFrame(probs_array, columns=['Class 0', 'Class 1', 'Class 2'])  # Add column names as per your classes\n","# Print the DataFrame\n","#print(probs_df)\n","\n","#-- Get the Drug names from Test Dataset and Scaler values of All variables\n","drug_names = test_data[['Drug']]\n","numpy_array = X_test.numpy()\n","X_test_scaler_df = pd.DataFrame(numpy_array, columns = X_test_df.columns)\n","#X_test_scaler_df\n","\n","#--- Merge Y_Test_Labels, Y_preds, Y_preds_Proabilites and test Dataset information also\n","concatenated_df = pd.concat([df, probs_df, drug_names, X_test_scaler_df], axis=1)\n","print (concatenated_df)\n","\n","#concatenated_df.to_csv('ML_results/Bayesian_Neural_nets_Preds.csv', index=False)  # Specify the desired file name and path"],"metadata":{"id":"HiX8zTfw1GV3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.Try Other Machine Learning NuSVC (Selected via comparing Multiple Machine Learning Based Models:\n","### Projects/Project_DILI/semenova_data/multiML_AZ_data.ipynb)"],"metadata":{"id":"c_vxQolb1NTU"}},{"cell_type":"code","source":["#NuSVC was selected because it was performing better than other ML methods\n","def sort_map(input_data):\n","    # Get the unique elements and their counts\n","    unique, counts = np.unique(input_data, return_counts=True)\n","    # Create a dictionary mapping each unique element to its count\n","    count_dict = dict(zip(unique, counts))\n","    # Sort the dictionary and return it\n","    return sorted(count_dict.items())\n","\n","# Read DataSET Again becuase for NN and BNN data was converted in to Tensor Objects\n","# Read the train and test datasets\n","train_data = pd.read_csv(\"Code_check/1-s2.0-S2468111320300438-mmc8.csv\")\n","test_data = pd.read_csv(\"Code_check/1-s2.0-S2468111320300438-mmc10.csv\")\n","\n","# Select the desired features from the datasets\n","features = ['ClogP', 'BSEP', 'Glu', 'Glu_Gal', 'THLE', 'HepG2', 'Fsp3', 'log10cmax']\n","X_train_df = train_data[features]\n","X_test_df = test_data[features]\n","\n","# Initialize a StandardScaler to standardize the features to have mean=0 and variance=1\n","scaler = StandardScaler()\n","\n","# Fit the StandardScaler on the training data and transform both training and test data\n","scaler.fit(X_train_df)\n","X_train = pd.DataFrame(scaler.transform(X_train_df), columns=X_train_df.columns)\n","X_test = pd.DataFrame(scaler.transform(X_test_df), columns=X_test_df.columns)\n","\n","# Select the target variable\n","target = ['dili_sev']\n","Y_train = (train_data[target].values.astype(int) - 1)\n","Y_test = (test_data[target].values.astype(int) - 1)\n","\n","# Apply the sort_map function on the target variable\n","sorted_train_output = sort_map(Y_train)\n","sorted_test_output = sort_map(Y_test)\n","\n","# Print the sorted output\n","print(sorted_train_output)\n","print(sorted_test_output)\n"],"metadata":{"id":"vKzUBLGs1I5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import numpy as np\n","from sklearn.pipeline import make_pipeline\n","from sklearn.pipeline import Pipeline\n","#from sklearn.preprocessing import StandardScaler\n","from sklearn.inspection import permutation_importance\n","from sklearn.model_selection import cross_val_score\n","from sklearn.svm import NuSVC\n","check = make_pipeline(StandardScaler(), NuSVC())\n","check.fit(X_train, Y_train)\n","Pipeline(steps=[('standardscaler', StandardScaler()), ('nusvc', NuSVC())])\n","\n","Y_train = Y_train.ravel()\n","Y_test = Y_test.ravel()\n","\n","#set_seed(110)\n","\n","#-- Check Performance of NuSVC using Multiple Kernels\n","#******************************* LINEAR Kernal\n","# Create a NuSVC object with a linear kernel\n","model_linear = NuSVC(kernel='linear', probability=True)\n","# Fit the classifier to the training data\n","model_linear.fit(X_train, Y_train)\n","\n","#----- Get Cross Validation Performances\n","cv_scores_linear = cross_val_score(model_linear, X_train, Y_train, cv=5, scoring='accuracy')\n","# Print the cross-validation scores\n","print(\"Cross-Validation Scores: Linear Kernal\", cv_scores_linear)\n","print(\"Mean Cross-Validation Score: Linear Kernal\", cv_scores_linear.mean())\n","\n","# Get the predictions on the test data\n","predictions_linear = model_linear.predict(X_test)\n","#--- Get prediction probabilites\n","probabilites_linear = model_linear.predict_proba(X_test)\n","# Get the performance metrics\n","metrics_linear = model_linear.score(X_test, Y_test)\n","# Print the performance metrics\n","print('Linear Kernel - Accuracy on Test Data')\n","print(metrics_linear)\n","from sklearn.metrics import confusion_matrix\n","conf_mat_linear = confusion_matrix(Y_test, predictions_linear)\n","print('Linera Kernel Confusion Matrix')\n","print(conf_mat_linear)\n","\n","#******************************* RBF Kernal\n","# Create a NuSVC object with an RBF kernel\n","model_rbf = NuSVC(kernel='rbf', probability=True)\n","# Fit the classifier to the training data\n","model_rbf.fit(X_train, Y_train)\n","\n","#----- Get Cross Validation Performances\n","cv_scores_rbf = cross_val_score(model_rbf, X_train, Y_train, cv=5, scoring='accuracy')\n","# Print the cross-validation scores\n","print(\"Cross-Validation Scores: RBF Kernal\", cv_scores_rbf)\n","print(\"Mean Cross-Validation Score: RBF Kernal\", cv_scores_rbf.mean())\n","\n","# Get the predictions on the test data\n","predictions_rbf = model_rbf.predict(X_test)\n","#--- Get prediction probabilites\n","probabilites_rbf = model_rbf.predict_proba(X_test)\n","# Get the performance metrics\n","metrics_rbf = model_rbf.score(X_test, Y_test)\n","# Print the performance metrics\n","print('RBF Kernel - Accuracy on the Test Data')\n","print(metrics_rbf)\n","from sklearn.metrics import confusion_matrix\n","conf_mat_rbf = confusion_matrix(Y_test, predictions_rbf)\n","print('RBF Kernel Confusion Matrix')\n","print(conf_mat_rbf)\n","\n","#******************************* POLYNOMIAL Kernal\n","# Create a NuSVC object with a polynomial kernel\n","model_poly = NuSVC(kernel='poly', probability=True)\n","# Fit the classifier to the training data\n","model_poly.fit(X_train, Y_train)\n","\n","#----- Get Cross Validation Performances\n","cv_scores_poly = cross_val_score(model_poly, X_train, Y_train, cv=5, scoring='accuracy')\n","# Print the cross-validation scores\n","print(\"Cross-Validation Scores: Poly Kernal\", cv_scores_poly)\n","print(\"Mean Cross-Validation Score: Poly Kernal\", cv_scores_poly.mean())\n","\n","# Get the predictions on the test data\n","predictions_poly = model_poly.predict(X_test)\n","#--- Get prediction probabilites\n","probabilites_poly = model_poly.predict_proba(X_test)\n","# Get the performance metrics\n","metrics_poly = model_poly.score(X_test, Y_test)\n","# Print the performance metrics\n","print('Polynomial Kernel - Accuracy on Test Data' )\n","print(metrics_poly)\n","from sklearn.metrics import confusion_matrix\n","conf_mat_poly = confusion_matrix(Y_test, predictions_poly)\n","print('Polynomial Kernel Confusion Matrix')\n","print(conf_mat_poly)"],"metadata":{"id":"70QhH5_x1em-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Y_test, predictions_linear, probabilites_linear\n","#Y_test, predictions_rbf, probabilities_rbf\n","Y_test, predictions_poly, probabilites_poly"],"metadata":{"id":"Y17WT7F01ii9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#----- Save Different Performance Matrices - RBF Kernal\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, precision_score, accuracy_score, f1_score, matthews_corrcoef, confusion_matrix\n","\n","# Compute precision, accuracy, F1-score, and MCC for the predicted and true labels\n","precision = precision_score(Y_test, predictions_rbf, average='macro')\n","accuracy = accuracy_score(Y_test, predictions_rbf)\n","f1_score = f1_score(Y_test, predictions_rbf, average='macro')\n","mcc = matthews_corrcoef(Y_test, predictions_rbf)\n","\n","# Calculate sensitivity and specificity using confusion matrix\n","cm = confusion_matrix(Y_test, predictions_rbf)\n","\n","# Calculate sensitivity and specificity for each class\n","sensitivity = {}\n","specificity = {}\n","\n","for i in range(cm.shape[0]):\n","    tp = cm[i, i]\n","    fn = sum(cm[i, :]) - tp\n","    fp = sum(cm[:, i]) - tp\n","    tn = cm.sum() - (tp + fn + fp)\n","\n","    sensitivity[i] = tp / (tp + fn)\n","    specificity[i] = tn / (tn + fp)\n","\n","# Calculate overall sensitivity and specificity\n","overall_sensitivity = sum(sensitivity.values()) / len(sensitivity)\n","overall_specificity = sum(specificity.values()) / len(specificity)\n","\n","# Print the performance metrics to the console\n","print(\"**************** MODEL PERFORMANCE: SuNVC RBF Model****************\")\n","print(\"Confusion Matrix:\")\n","print(cm)\n","print(\"Sensitivity:\")\n","for key, value in sensitivity.items():\n","    print(\"Class {}: {:.2f}\".format(key, value))\n","print(\"Specificity:\")\n","for key, value in specificity.items():\n","    print(\"Class {}: {:.2f}\".format(key, value))\n","print(\"Overall Sensitivity: {:.2f}\".format(overall_sensitivity))\n","print(\"Overall Specificity: {:.2f}\".format(overall_specificity))\n","\n","print(\"Precision: {:.2f}\".format(precision))\n","print(\"Accuracy: {:.2f}\".format(accuracy))\n","print(\"F1-score: {:.2f}\".format(f1_score))\n","print(\"MCC: {:.2f}\".format(mcc))"],"metadata":{"id":"5UK6-Tc01l1W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the NuSVC RBF Kernal Results\n","merged_array_rbf = np.column_stack((Y_test, predictions_rbf))\n","merged_array_rbf_df = pd.DataFrame(data=merged_array_rbf, columns=['Y_test', 'Y_predicted'])\n","#print (merged_array_rbf_df)\n","\n","# Convert predicted probabilities to a NumPy array\n","#probs_array = probabilities_rbf.detach().numpy()\n","# Create a DataFrame from the NumPy array\n","probs_rbf_df = pd.DataFrame(probabilites_rbf, columns=['Class 0', 'Class 1', 'Class 2'])  # Add column names as per your classes\n","# Print the DataFrame\n","#print(probs_df)\n","\n","#-- Get the Drug names from Test Dataset and Scaler values of All variables\n","drug_names = test_data[['Drug']]\n","\n","#--- Merge Y_Test_Labels, Y_preds, Y_preds_Proabilites and test Dataset information also\n","concatenated_rbf_df = pd.concat([merged_array_rbf_df, probs_rbf_df, drug_names, X_test], axis=1)\n","print (concatenated_rbf_df)\n","\n","#concatenated_rbf_df.to_csv('ML_results/NuSVC_RBF_Preds.csv', index=False)  # Specify the desired file name and path\n","\n","\n","# Save the NuSVC Polynomial Kernal Results\n","merged_array_poly = np.column_stack((Y_test, predictions_poly))\n","merged_array_poly_df = pd.DataFrame(data=merged_array_poly, columns=['Y_test', 'Y_predicted'])\n","#print (merged_array_poly_df)\n","\n","# Convert predicted probabilities to a NumPy array\n","#probs_array = probabilities_rbf.detach().numpy()\n","# Create a DataFrame from the NumPy array\n","probs_poly_df = pd.DataFrame(probabilites_poly, columns=['Class 0', 'Class 1', 'Class 2'])  # Add column names as per your classes\n","# Print the DataFrame\n","#print(probs_poly_df)\n","\n","#-- Get the Drug names from Test Dataset and Scaler values of All variables\n","drug_names = test_data[['Drug']]\n","\n","#numpy_array = X_test.numpy()\n","#X_test_scaler_df = pd.DataFrame(numpy_array, columns = X_test_df.columns)\n","#X_test_scaler_df\n","\n","#--- Merge Y_Test_Labels, Y_preds, Y_preds_Proabilites and test Dataset information also\n","concatenated_poly_df = pd.concat([merged_array_poly_df, probs_poly_df, drug_names, X_test], axis=1)\n","print (concatenated_poly_df)\n","\n","#concatenated_poly_df.to_csv('ML_results/NuSVC_Polynomial_Preds.csv', index=False)  # Specify the desired file name and path"],"metadata":{"id":"70IIbWfn1o-N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#####Save prediction probabilites figures on the Test DataSet for each Molecule - Using Polynomial Kernel - One time Task\n","#-- This Code is to Bar Plot the Prediction probabilites for Each Compound Along with the Dot plot all Assay Parameters Associated\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Example dataframe\n","#df = pd.DataFrame({\n","#    'Compound': ['A', 'B', 'C'],\n","#    'Class 1': [0.6, 0.2, 0.4],\n","#    'Class 2': [0.3, 0.1, 0.5],\n","#    'Class 3': [0.1, 0.7, 0.1],\n","#    'Y_test': ['Class 1', 'Class 3', 'Class 1'],\n","#    'bsep': [100, 300, 400],\n","#    'lop': [3, -4, 1],\n","#    'cmax': [150, 20, 100],\n","#    'glu': [1, 0.1, 0.5],\n","#    'glu-gal': [20, 70, 50],\n","#    'fsp3': [1000, 150, 800]\n","#})\n","\n","#----------------For Polynomial Kernal\n","#concatenated_poly_df <- pd.read_csv(\"ML_results/NuSVC_Polynomial_Preds.csv\")\n","# Reoder the Columns in the concatenated_poly_df file\n","#df = concatenated_poly_df.loc[:, ['Drug','Class 0','Class 1','Class 2','Y_test','ClogP','BSEP','Glu','Glu_Gal','THLE','HepG2','Fsp3','log10cmax']]\n","\n","#-------------- For RBF Kernal\n","#concatenated_rbf_df <- pd.read_csv(\"ML_results/NuSVC_RBF_Preds.csv\")\n","# Reoder the Columns in the concatenated_poly_df file\n","df = concatenated_rbf_df.loc[:, ['Drug','Class 0','Class 1','Class 2','Y_test','ClogP','BSEP','Glu','Glu_Gal','THLE','HepG2','Fsp3','log10cmax']]\n","\n","# Set the width of the bars\n","bar_width = 0.2\n","\n","# Set the positions of the bars on the x-axis\n","bar_positions = np.arange(len(df.columns[1:4]))\n","\n","# Create a color map for the prediction probabilities\n","color_map = ['#008b00', '#b8860b', '#b22222']\n","\n","#--- Get the Value Ranges to Add on the Dot Plot\n","range_cols = df.columns[5:]\n","# Set the range for the dot plot\n","x_range = [df[range_cols].min().min(), df[range_cols].max().max()]\n","x_min = df[range_cols].values.min()\n","x_max = df[range_cols].values.max()\n","\n","# Loop over each compound and save the plot as an image\n","for i, compound in enumerate(df['Drug']):\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n","\n","    # Bar Plot\n","    prediction_probs = df.iloc[i, 1:4]\n","    ax1.bar(bar_positions, prediction_probs, width=bar_width, color=color_map)\n","\n","    # Customize the plot\n","    ax1.set_xticks(bar_positions)\n","    ax1.set_xticklabels(df.columns[1:4])\n","    ax1.set_xlabel('')\n","    ax1.set_ylabel('Prediction Probability')\n","    ax1.set_title(f'Compound name- {compound} - (True Label: {df[\"Y_test\"].iloc[i]})')\n","\n","    # Dot Plot\n","    for j, col in enumerate(df.columns[5:]):\n","        if col in range_cols:\n","            ax2.plot([df[col].iloc[i]], [j], 'o', color='blue')  # Dot plot\n","\n","    for j, col in enumerate(range_cols):\n","        ax2.hlines(y=j, xmin=df[col].min(), xmax=df[col].max(), colors='gray', linestyles='dashed', linewidth=1)\n","\n","    # Customize the plot\n","    ax2.set_yticks(range(len(range_cols)))\n","    ax2.set_yticklabels(range_cols)\n","    ax2.set_xlabel('Values')\n","    ax2.set_ylabel('Variables')\n","    ax2.set_title(f'Compound name {compound}')\n","    ax2.set_xlim(x_min, x_max)\n","\n","    # Save the plot as an image\n","    plt.subplots_adjust(wspace=0.5)\n","    #---- For Polynomial Kernal\n","    #plt.savefig(f'ML_results/Predictions_NuSVC/Polynomial/{compound}_plot.png')\n","    #---- For RBF Kernal\n","    plt.savefig(f'ML_results/Predictions_NuSVC/RBF/{compound}_plot.png')\n","    plt.close()"],"metadata":{"id":"zFvVi6KJ1sEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### Save prediction probabilites figures on the Test DataSet for each Molecule - Using RBF Kernel -  - One time Task\n","#-- This Code is to Bar Plot the Prediction probabilites for Each Compound Along with the Dot plot all Assay Parameters Associated\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Example dataframe\n","#df = pd.DataFrame({\n","#    'Compound': ['A', 'B', 'C'],\n","#    'Class 1': [0.6, 0.2, 0.4],\n","#    'Class 2': [0.3, 0.1, 0.5],\n","#    'Class 3': [0.1, 0.7, 0.1],\n","#    'Y_test': ['Class 1', 'Class 3', 'Class 1'],\n","#    'bsep': [100, 300, 400],\n","#    'lop': [3, -4, 1],\n","#    'cmax': [150, 20, 100],\n","#    'glu': [1, 0.1, 0.5],\n","#    'glu-gal': [20, 70, 50],\n","#    'fsp3': [1000, 150, 800]\n","#})\n","\n","#concatenated_poly_df <- pd.read_csv(\"ML_results/NuSVC_Polynomial_Preds.csv\")\n","# Reoder the Columns in the concatenated_poly_df file\n","df = concatenated_rbf_df.loc[:, ['Drug','Class 0','Class 1','Class 2','Y_test','ClogP','BSEP','Glu','Glu_Gal','THLE','HepG2','Fsp3','log10cmax']]\n","\n","# Set the width of the bars\n","bar_width = 0.2\n","\n","# Set the positions of the bars on the x-axis\n","bar_positions = np.arange(len(df.columns[1:4]))\n","\n","# Create a color map for the prediction probabilities\n","color_map = ['#008b00', '#b8860b', '#b22222']\n","\n","#--- Get the Value Ranges to Add on the Dot Plot\n","range_cols = df.columns[5:]\n","# Set the range for the dot plot\n","x_range = [df[range_cols].min().min(), df[range_cols].max().max()]\n","x_min = df[range_cols].values.min()\n","x_max = df[range_cols].values.max()\n","\n","# Loop over each compound and save the plot as an image\n","for i, compound in enumerate(df['Drug']):\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n","\n","    # Bar Plot\n","    prediction_probs = df.iloc[i, 1:4]\n","    ax1.bar(bar_positions, prediction_probs, width=bar_width, color=color_map)\n","\n","    # Customize the plot\n","    ax1.set_xticks(bar_positions)\n","    ax1.set_xticklabels(df.columns[1:4])\n","    ax1.set_xlabel('')\n","    ax1.set_ylabel('Prediction Probability')\n","    ax1.set_title(f'Compound name- {compound} - (True Label: {df[\"Y_test\"].iloc[i]})')\n","\n","    # Dot Plot\n","    for j, col in enumerate(df.columns[5:]):\n","        if col in range_cols:\n","            ax2.plot([df[col].iloc[i]], [j], 'o', color='blue')  # Dot plot\n","\n","    for j, col in enumerate(range_cols):\n","        ax2.hlines(y=j, xmin=df[col].min(), xmax=df[col].max(), colors='gray', linestyles='dashed', linewidth=1)\n","\n","    # Customize the plot\n","    ax2.set_yticks(range(len(range_cols)))\n","    ax2.set_yticklabels(range_cols)\n","    ax2.set_xlabel('Values')\n","    ax2.set_ylabel('Variables')\n","    ax2.set_title(f'Compound name {compound}')\n","    ax2.set_xlim(x_min, x_max)\n","\n","    # Save the plot as an image\n","    plt.subplots_adjust(wspace=0.5)\n","    plt.savefig(f'ML_results/Predictions_NuSVC/RBF/{compound}_plot.png')\n","    plt.close()"],"metadata":{"id":"V_jMlNXI1xMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","\n","# Directory containing the images\n","#-- For Polynomial Kernal\n","#image_dir = '~/Project_DILI/semenova_data/ML_results/Predictions_NuSVC/RBF/'\n","#-- For RBF Kernal\n","image_dir = '~/Project_DILI/semenova_data/ML_results/Predictions_NuSVC/RBF/'\n","\n","\n","# Get a list of image file names in the directory\n","image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n","\n","# Sort the image files by name (if necessary)\n","image_files.sort()\n","\n","# Create a list to store the frames of the animation\n","frames = []\n","\n","# Load each image and append it to the frames list\n","for image_file in image_files:\n","    image_path = os.path.join(image_dir, image_file)\n","    image = Image.open(image_path)\n","    frames.append(image)\n","\n","# Create the animation (Play with the Duration to speed up or Slow the animation Speed)\n","animation = Image.new('RGB', frames[0].size)\n","#-- For Polynomial Kernal\n","#animation.save('ML_results/NuSVC_Polynomial_Preds_Animation.gif', format='GIF', append_images=frames[1:], save_all=True, duration=10, loop=0)\n","#-- For RBF Kernal\n","animation.save('ML_results/NuSVC_RBF_Preds_Animation.gif', format='GIF', append_images=frames[1:], save_all=True, duration=10, loop=0)"],"metadata":{"id":"ZWKLjcSQ2BxV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Feature Importance Calculation using All three models\n","from sklearn.inspection import permutation_importance\n","import matplotlib.pyplot as plt\n","\n","# Calculate feature importances using permutation importance\n","result_rbf = permutation_importance(model_rbf, X_test, Y_test, n_repeats=10, random_state=42)\n","# Get the mean importance score for each feature\n","importances_rbf = result_rbf.importances_mean\n","# Sort the feature importances in descending order\n","sorted_indices_rbf = np.argsort(importances_rbf)[::-1]\n","# Print the feature importances\n","for idx in sorted_indices_rbf:\n","    print(f\"Feature {idx}: RBF Model: importance score {importances_rbf[idx]}\")\n","\n","# Create a bar plot of the feature importances\n","plt.bar(range(X_test.shape[1]), importances_rbf[sorted_indices_rbf])\n","plt.xticks(range(X_test.shape[1]), sorted_indices_rbf)\n","plt.title(\"Feature importances (RBF Model)\")\n","plt.show()\n","plt.savefig('ML_results/FeaturesImportance_NuSVC_RBF.png', dpi=300)\n","\n","# Get the names of the features\n","feature_names = np.array(X_train_df.columns.values)\n","\n","# Create a bar plot of the feature importances\n","plt.bar(range(X_test.shape[1]), importances_rbf[sorted_indices_rbf])\n","plt.xticks(range(X_test.shape[1]), feature_names[sorted_indices_rbf], rotation=90)\n","plt.title(\"Feature importances with Names (RBF Model)\")\n","plt.show()\n","plt.savefig('ML_results/FeaturesImportanceNames_NuSVC_RBF.png', dpi=300)"],"metadata":{"id":"AxRwagD12PKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### Optimize Other Parameters of RBF Kernal NuSVC\n","# Load Libraries\n","# Data reading in Dataframe format and data preprocessing\n","import pandas as pd\n","pd.set_option(\"display.max_columns\", 160)\n","import numpy as np\n","\n","# Data Visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Dataset Creation\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit, GridSearchCV\n","\n","# Dataset Processing\n","from sklearn import datasets, linear_model, metrics\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","# Model Development\n","from sklearn.pipeline import make_pipeline, Pipeline\n","from sklearn.linear_model import Ridge\n","from sklearn.svm import SVC\n","\n","# Model Evaluation\n","from sklearn.metrics import r2_score, confusion_matrix, ConfusionMatrixDisplay\n","from yellowbrick.classifier import ClassificationReport, ClassPredictionError\n","from yellowbrick.regressor import ResidualsPlot, PredictionError\n","\n","# Feature Importance\n","import shap"],"metadata":{"id":"WImaMUv12ScN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import Ridge\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import r2_score\n","\n","ridge_pipeline = make_pipeline(Ridge(alpha=10))\n","ridge_pipeline.fit(X_train, Y_train)\n","hat_y_test = ridge_pipeline.predict(X_test)\n","\n","fig, ax = plt.subplots(1)\n","sns.regplot(data=None, x=Y_test, y=hat_y_test, line_kws={\"color\":\"black\", \"linestyle\":\"dotted\"})\n","plt.plot()\n","plt.savefig('ML_results/regression_plot.png', dpi=300)\n","ax.set(xlabel=r\"y\", ylabel=r\"y'\")\n","test_r2_score_ = r2_score(Y_test, hat_y_test)\n","print(f\"R2 score: {test_r2_score_}\")"],"metadata":{"id":"OD4lZ48i2hri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#**************************************************************************\n","#------ Alternative to Check the Brier Score for Each Class\n","import numpy as np\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import NuSVC\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.metrics import brier_score_loss\n","\n","# Create an uncalibrated NuSVC model\n","model_rbf = NuSVC(kernel='rbf', probability=True)\n","\n","# Fit the model to the training data\n","model_rbf.fit(X_train, Y_train)\n","\n","# Get the predicted probabilities on the test data\n","probabilities = model_rbf.predict_proba(X_test)\n","\n","# Calibrate the predicted probabilities using CalibratedClassifierCV\n","calibrated_model_rbf = CalibratedClassifierCV(model_rbf, cv=5)\n","calibrated_model_rbf.fit(X_train, Y_train)\n","calibrated_probabilities = calibrated_model_rbf.predict_proba(X_test)\n","\n","# Compute the Brier score for each class\n","brier_scores = []\n","for class_idx in range(probabilities.shape[1]):\n","    true_labels = np.zeros_like(Y_test)\n","    true_labels[Y_test == class_idx] = 1\n","    uncalibrated_brier_score = brier_score_loss(true_labels, probabilities[:, class_idx])\n","    calibrated_brier_score = brier_score_loss(true_labels, calibrated_probabilities[:, class_idx])\n","    brier_scores.append((uncalibrated_brier_score, calibrated_brier_score))\n","\n","# Print the Brier scores for each class\n","for class_idx, (uncalibrated_score, calibrated_score) in enumerate(brier_scores):\n","    print(f\"Class {class_idx}:\")\n","    print(f\"  Uncalibrated Brier Score: {uncalibrated_score}\")\n","    print(f\"  Calibrated Brier Score: {calibrated_score}\")"],"metadata":{"id":"8kaRnd232k5w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. POLR Method as used by Semenova Et Al."],"metadata":{"id":"swhZXiiH2qSV"}},{"cell_type":"code","source":["# design matrices\n","from patsy import dmatrix\n","\n","#- Number of columns increased likely due to the addition of the quadratic terms and interactions specified in the dmatrix formula string\n","# Quadratic terms for these variables in the resulting design matrix. This means that for each of these variables, two new columns are added to the design matrix: one with the original variable values, and one with the squared variable values.\n","# Additionally, the formula string includes the + operator between each of the variables, which instructs dmatrix to include interaction terms between the variables in the resulting design matrix. This means that for each pair of variables, a new column is added to the design matrix with the product of the two variable values.\n","\n","X_train_new = pd.DataFrame(dmatrix(\"0 + (ClogP + BSEP + THLE + Glu + Glu_Gal + HepG2 + Fsp3)**2 + log10cmax\", X_train))\n","X_test_new = pd.DataFrame(dmatrix(\"0 + (ClogP + BSEP + THLE + Glu + Glu_Gal + HepG2 + Fsp3)**2 + log10cmax\", X_test))\n","\n","y_train_new = train_data['dili_sev'].values #--- Y_shared-1 was used while creating the model\n","y_test_new = test_data['dili_sev'].values"],"metadata":{"id":"EEJwJf-32luZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## ---------------------------------------------------------\n","## Define and fit model\n","## ---------------------------------------------------------\n","\n","N = X_train_new.shape[0]\n","p = X_train_new.shape[1]\n","X_train_new = X_train_new.values\n","#y_train.reshape((96,1));\n","sigma_prior = 1\n","\n","# share variable to enable predictions\n","X_shared = theano.shared(X_train_new)\n","y_shared = theano.shared(y_train_new)\n","\n","with pm.Model() as model:\n","\n","    mu_beta = pm.Normal('mu_beta', mu=0, sd=2)\n","    sd_beta = pm.HalfNormal('sd', sd=sigma_prior)\n","    beta = pm.Laplace('beta', mu=mu_beta, b=sd_beta, shape=p)\n","\n","    cutpoints = pm.Normal(\"cutpoints\", mu=[-0.001,0], sd=20, shape=2,\n","                           transform=pm.distributions.transforms.ordered)\n","\n","    lp = pm.Deterministic('lp', pm.math.dot(X_shared, beta))\n","\n","    y_obs = pm.OrderedLogistic(\"y_obs\", eta=lp, cutpoints=cutpoints, observed=y_shared-1)\n","\n","    trace = pm.sample(draws = 20000) #Try changing pm.sample(samples=20000) to pm.sample(draws=20000) and see if it resolves the issue."],"metadata":{"id":"3UEGb4us2vjR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import pickle\n","\n","#***************** Save Trace and Model\n","#----------Save the trace\n","#with open(\"Final_models/SemenovaData_POLR_trace.pkl\", \"wb\") as file:\n","#    pickle.dump(trace, file)\n","#----------Save the model\n","#with open(\"Final_models/SemenovaData_POLR_model.pkl\", \"wb\") as file:\n","#    pickle.dump(model, file)\n","\n","#***************** Load Trace and Model\n","#------------ Load the trace\n","#with open(\"Final_models/SemenovaData_POLR_trace.pkl\", \"rb\") as file:\n","#    trace = pickle.load(file)\n","\n","#------------ Load the model\n","#with open(\"Final_models/SemenovaData_POLR_model.pkl\", \"rb\") as file:\n","#    model = pickle.load(file)"],"metadata":{"id":"VXBw15oo2zrC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import arviz as az\n","#az.plot_trace(trace)\n","\n","with model:\n","    az.plot_trace(trace)"],"metadata":{"id":"RghOWPMO22o2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summary\n","pm.summary(trace).round(2)"],"metadata":{"id":"q6ESwjd23ANM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## ---------------------------------------------------------\n","## predict for training data\n","## ---------------------------------------------------------\n","post_pred_train = pm.sample_posterior_predictive(trace, samples=5000, model=model)\n","\n","# exctract predictions\n","y_pred_train_df = post_pred_train['y_obs']\n","# Get predicted probabilities\n","y_pred_probs_mean = np.mean(post_pred_train['y_obs'], axis=0)"],"metadata":{"id":"SN3GxrBT3D4_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize predictions\n","y_pred_train_df\n","y_pred_train_df.shape # 5000 times 147 Columns (Data) - For Each compound get which class got majority votes\n","y_pred_train_df_df = pd.DataFrame(y_pred_train_df)\n","\n","import pandas as pd\n","import numpy as np\n","from scipy.stats import mode\n","\n","# Assuming you have a NumPy array called 'y_pred_train_df' with shape (5000, 147)\n","# Each column contains three predicted labels\n","\n","# Convert the NumPy array to a DataFrame\n","df = pd.DataFrame(y_pred_train_df_df)\n","\n","# Get the label with the majority of votes for each column\n","majority_labels = np.asarray(mode(df, axis=0)[0])[0]\n","\n","# Print the majority labels\n","print(majority_labels)\n","\n","# Just check\n","y_pred_train_df[0].value_counts()"],"metadata":{"id":"p7pwD2rn3G18"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_train_updated = y_train_new.astype(int) - 1 # Y-actual lables were 1,2,3 but in model 0,1,2 was used\n","train_actual_pred = np.column_stack((Y_train_updated, majority_labels))\n","train_actual_pred_df = pd.DataFrame(data=train_actual_pred, columns=['Train_actual_label', 'Train_pred_label'])\n","train_actual_pred_df\n","train_actual_pred_df.to_csv('ML_results/POLR_trainData_Perform.csv', index=False)  # Specify the desired file name and path"],"metadata":{"id":"C9GUqeep3KWV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#----- Save Different Performance Matrices\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, precision_score, accuracy_score, f1_score, matthews_corrcoef, confusion_matrix\n","\n","# Compute precision, accuracy, F1-score, and MCC for the predicted and true labels\n","precision = precision_score(Y_train_updated, majority_labels, average='macro')\n","accuracy = accuracy_score(Y_train_updated, majority_labels)\n","f1_score = f1_score(Y_train_updated, majority_labels, average='macro')\n","mcc = matthews_corrcoef(Y_train_updated, majority_labels)\n","\n","# Calculate sensitivity and specificity using confusion matrix\n","cm = confusion_matrix(Y_train_updated, majority_labels)\n","\n","# Calculate sensitivity and specificity for each class\n","sensitivity = {}\n","specificity = {}\n","\n","for i in range(cm.shape[0]):\n","    tp = cm[i, i]\n","    fn = sum(cm[i, :]) - tp\n","    fp = sum(cm[:, i]) - tp\n","    tn = cm.sum() - (tp + fn + fp)\n","\n","    sensitivity[i] = tp / (tp + fn)\n","    specificity[i] = tn / (tn + fp)\n","\n","# Calculate overall sensitivity and specificity\n","overall_sensitivity = sum(sensitivity.values()) / len(sensitivity)\n","overall_specificity = sum(specificity.values()) / len(specificity)\n","\n","# Print the performance metrics to the console\n","print(\"**************** MODEL PERFORMANCE: POLR on Training Dataset ****************\")\n","print(\"Confusion Matrix:\")\n","print(cm)\n","print(\"Sensitivity:\")\n","for key, value in sensitivity.items():\n","    print(\"Class {}: {:.2f}\".format(key, value))\n","print(\"Specificity:\")\n","for key, value in specificity.items():\n","    print(\"Class {}: {:.2f}\".format(key, value))\n","print(\"Overall Sensitivity: {:.2f}\".format(overall_sensitivity))\n","print(\"Overall Specificity: {:.2f}\".format(overall_specificity))\n","\n","print(\"Precision: {:.2f}\".format(precision))\n","print(\"Accuracy: {:.2f}\".format(accuracy))\n","print(\"F1-score: {:.2f}\".format(f1_score))\n","print(\"MCC: {:.2f}\".format(mcc))"],"metadata":{"id":"wz83QC6f3NNN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#---- Now do the Predictions on Test Data\n","# ### Predict for test data\n","X_shared.set_value(X_test_new)\n","y_shared.set_value([0, 0]) # dummy values\n","post_pred_test = pm.sample_posterior_predictive(trace, samples=5000, model=model)\n","\n","y_pred_test_df = post_pred_test['y_obs']\n","y_pred_test_df.shape"],"metadata":{"id":"8KixFHzO3P3E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# posterior prediction for each category\n","def probs(y_pred_df, ind):\n","    y_pred_ind = y_pred_df[:,ind]\n","    p = [sum(y_pred_ind == 0)/len(y_pred_ind), sum(y_pred_ind == 1)/len(y_pred_ind), sum(y_pred_ind == 2)/len(y_pred_ind)]\n","    return p\n","\n","# compute posterior probabilities for a selected drug\n","print(probs(y_pred_test_df, 0))\n","print(probs(y_pred_test_df, 1))\n","print(probs(y_pred_test_df, 2))"],"metadata":{"id":"iD6KUAWm3Sqq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize predictions on The Test DataSet\n","y_pred_test_df\n","y_pred_test_df.shape # 5000 times 37 Columns (Data) - For Each compound get which class got majority votes\n","y_pred_test_df_df = pd.DataFrame(y_pred_test_df)\n","\n","import pandas as pd\n","import numpy as np\n","from scipy.stats import mode\n","\n","# Assuming you have a NumPy array called 'y_pred_train_df' with shape (5000, 147)\n","# Each column contains three predicted labels\n","\n","# Convert the NumPy array to a DataFrame\n","df = pd.DataFrame(y_pred_test_df_df)\n","\n","# Get the label with the majority of votes for each column\n","pred_majority_labels = np.asarray(mode(df, axis=0)[0])[0]\n","\n","# Print the majority labels\n","print(pred_majority_labels)\n","\n","# Just check\n","y_pred_test_df_df[0].value_counts()"],"metadata":{"id":"v0Sfhrc73VGx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_test_updated = y_test_new.astype(int) - 1 # Y-actual lables were 1,2,3 but in model 0,1,2 was used\n","test_actual_pred = np.column_stack((Y_test_updated, pred_majority_labels))\n","test_actual_pred_df = pd.DataFrame(data=test_actual_pred, columns=['Test_actual_label', 'Test_pred_label'])\n","test_actual_pred_df"],"metadata":{"id":"BFNU8eTG3Xm0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Initialize an empty DataFrame\n","probabilities_df = pd.DataFrame()\n","\n","# Iterate over the instances and extract probabilities\n","class_index = 0  # Index of the desired class\n","for i in range(37):\n","    instance_probs = probs(y_pred_test_df, i)\n","    probabilities_df = probabilities_df.append(pd.Series(instance_probs), ignore_index=True)\n","\n","# Set column names for the probabilities DataFrame\n","probabilities_df.columns = ['Class 1', 'Class 2', 'Class 3']\n","\n","# Print the probabilities DataFrame\n","print(probabilities_df)"],"metadata":{"id":"V-WbCOFK3aYW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save Prediction Results of POLR model on Test Dataset\n","# test_actual_pred_df - has actual and predicted lables\n","# print (test_actual_pred_df)\n","# probabilities_df - has all three probabilities\n","# print(probabilities_df)\n","#-- Get the Drug names from Test Dataset and Scaler values of All variables\n","drug_names = test_data[['Drug']]\n","\n","#--- Merge Y_Test_Labels, Y_preds, Y_preds_Proabilites and test Dataset information also\n","POLR_concatenated_df = pd.concat([test_actual_pred_df, probabilities_df, drug_names, X_test], axis=1)\n","print (POLR_concatenated_df)\n","\n","POLR_concatenated_df.to_csv('ML_results/POLR_testData_Predictions.csv', index=False)  # Specify the desired file name and path"],"metadata":{"id":"OTyf6OeN3dS9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#----- Check Different Performance Matrices on Test Data Set\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, precision_score, accuracy_score, f1_score, matthews_corrcoef, confusion_matrix\n","\n","# Compute precision, accuracy, F1-score, and MCC for the predicted and true labels\n","precision = precision_score(Y_test_updated, pred_majority_labels, average='macro')\n","accuracy = accuracy_score(Y_test_updated, pred_majority_labels)\n","f1_score = f1_score(Y_test_updated, pred_majority_labels, average='macro')\n","mcc = matthews_corrcoef(Y_test_updated, pred_majority_labels)\n","\n","# Calculate sensitivity and specificity using confusion matrix\n","cm = confusion_matrix(Y_test_updated, pred_majority_labels)\n","\n","# Calculate sensitivity and specificity for each class\n","sensitivity = {}\n","specificity = {}\n","\n","for i in range(cm.shape[0]):\n","    tp = cm[i, i]\n","    fn = sum(cm[i, :]) - tp\n","    fp = sum(cm[:, i]) - tp\n","    tn = cm.sum() - (tp + fn + fp)\n","\n","    sensitivity[i] = tp / (tp + fn)\n","    specificity[i] = tn / (tn + fp)\n","\n","# Calculate overall sensitivity and specificity\n","overall_sensitivity = sum(sensitivity.values()) / len(sensitivity)\n","overall_specificity = sum(specificity.values()) / len(specificity)\n","\n","# Print the performance metrics to the console\n","print(\"**************** MODEL PERFORMANCE: POLR on Training Dataset ****************\")\n","print(\"Confusion Matrix:\")\n","print(cm)\n","print(\"Sensitivity:\")\n","for key, value in sensitivity.items():\n","    print(\"Class {}: {:.2f}\".format(key, value))\n","print(\"Specificity:\")\n","for key, value in specificity.items():\n","    print(\"Class {}: {:.2f}\".format(key, value))\n","print(\"Overall Sensitivity: {:.2f}\".format(overall_sensitivity))\n","print(\"Overall Specificity: {:.2f}\".format(overall_specificity))\n","\n","print(\"Precision: {:.2f}\".format(precision))\n","print(\"Accuracy: {:.2f}\".format(accuracy))\n","print(\"F1-score: {:.2f}\".format(f1_score))\n","print(\"MCC: {:.2f}\".format(mcc))"],"metadata":{"id":"V4CapQjv3kQ_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### `Final BNN Code is in the seperate File (BNN_Check.ipynb). That BNN model was developed using the same parameters used in the origional paper.`"],"metadata":{"id":"i5Rl1OYD28fo"}}]}